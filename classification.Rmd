---
title: "classification"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Questions before/during reading:

1. maths behind logistic function? 

2. what is log-odds/logit? 
  - "logistic regression model, increasing X by one unit changes the log odds by $\beta_1$ or equivalently multiplies the odds by $e^{\beta_1}$"
  - "a one-uni increase in balance is associated withan increase in the log odds of default by 0.0055 units" (p.134)... what does that mean?

3. "The estimated intercept in Table 4.1 is typically not of interest" (p.134)...why?

4. maximum likelihood vs least squares?

```{r}
set.seed(22)
library(tidyverse)
library(mlbench)
library(tidyverse)
library(janitor)
library(caTools)
library(psych)
library(devtools)
library(MASS)
library(klaR)
library(ggord)
# install_github("fawda123/ggord")
```

# LDA with iris data
[Linear Discriminant Analysis in R | Example with Classification Model & Bi-Plot interpretation](https://www.youtube.com/watch?v=WUCnHx0QDSI)
- estimate relationship between a single categorical DV and a set of quantitative IVs

## model  
```{r}
set.seed(555)

pairs.panels(mydat[1:4],
             bg=c("red","yellow","blue")[mydat$Species],
             pch=21)

ind <- sample(2, nrow(mydat),
              replace = TRUE, 
              prob = c(.7, .3))

training <- iris[ind==1,]
testing <- iris[ind==2,]

m1 <- lda(Species ~ ., training)
m1

m1$prior
m1$counts

```

## histograms
```{r}
pred <- predict(m1, training)

pred$class
pred$posterior
pred$x

ldahist(data = pred$x[,1], g = training$Species) # LD1
ldahist(data = pred$x[,2], g = training$Species) # LD2

ggord(m1, training$Species, ylim= c(-10,10))

```

## partition plot
- linear vs quadratic 
```{r}
partimat(Species ~., data = training, method = "lda") 
partimat(Species ~., data = training, method = "qda")
```

## Confusion Matrix - training data
```{r}
p1 <- predict(m1, training)$class

conf_mat <- table(Predicted = p1, Actual = training$Species)

acc <- sum(diag(conf_mat))/sum(conf_mat)
acc 
```

## Confusion Matrix - testing data
```{r}
p2 <- predict(m1, testing)$class

conf_mat_test <- table(Predicted = p2, Actual = testing$Species)

acc <- sum(diag(conf_mat_test))/sum(conf_mat_test)
acc
```


# Breast Cancer classification problem
```{r}

data(BreastCancer)

bc_data_raw <- BreastCancer %>%
  as_tibble() %>%
  clean_names()

str(bc_data_raw)

sum(is.na(bc_data_raw))

# going to reduce data set down to 4 variables of interest
bc_data <- bc_data_raw %>%
  na.omit() %>%
  select(cl_thickness, cell_size, cell_shape, marg_adhesion, class)

str(bc_data)

# let's reduce the number of factor levels from 10 to 3
table(bc_data$cl_thickness) 
table(bc_data$cell_size) 
table(bc_data$cell_shape) 
table(bc_data$marg_adhesion) 

bc_data_clean <- bc_data %>%
  mutate(across(cl_thickness:marg_adhesion, ~ case_when(.x %in% c(1,2,3) ~ "Low", 
                                   .x %in% c(4,5,6,7) ~ "Medium",
                                   .x %in% c(8,9,10) ~ "High"))) %>%
  na.omit()

str(bc_data_clean)

bc_data_clean$cl_thickness <- factor(bc_data_clean$cl_thickness, levels = c("Low", "Medium", "High"))
bc_data_clean$cell_size <- factor(bc_data_clean$cell_size, levels = c("Low", "Medium", "High"))
bc_data_clean$cell_shape <- factor(bc_data_clean$cell_shape, levels = c("Low", "Medium", "High"))
bc_data_clean$marg_adhesion <- factor(bc_data_clean$marg_adhesion, levels = c("Low", "Medium", "High"))
```


# Data visualisation 
```{r}
ggplot(bc_data_clean, aes(cl_thickness)) +
  geom_bar(aes(fill=class), color="black") +
  theme_bw()

ggplot(bc_data_clean, aes(cell_size)) +
  geom_bar(aes(fill=class), color="black") +
  theme_bw()

ggplot(bc_data_clean, aes(cell_shape)) +
  geom_bar(aes(fill=class), color="black") +
  theme_bw()

ggplot(bc_data_clean, aes(marg_adhesion)) +
  geom_bar(aes(fill=class), color="black") +
  theme_bw()


```

# Split into training and testing data
```{r}
bc_data_clean$split <- sample.split(bc_data_clean$class, SplitRatio = 0.7)

bc_train <- bc_data_clean %>%
  filter(split == TRUE)

bc_test <- bc_data_clean %>%
  filter(split == FALSE)

bc_model <- glm(class ~ ., family = binomial(link = "logit"), data = bc_train)
summary(bc_model)

bc_test$predicted_class <- predict(bc_model, newdata = bc_test, type = "response") # not sure what this warning is?? 

# confusion matrix
confusion_mat <- table(bc_test$class, bc_test$predicted_class > 0.5) # compares actual class to predicted class 
confusion_mat

acc <- (confusion_mat[1,1]+confusion_mat[2,2])/sum(confusion_mat)
# model is 96% accurate
```

